{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "THUCNews.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo8zMmstc1b5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# coding: utf-8\n",
        "\n",
        "import sys\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow.keras as kr\n",
        "\n",
        "if sys.version_info[0] > 2:\n",
        "    is_py3 = True\n",
        "else:\n",
        "    reload(sys)\n",
        "    sys.setdefaultencoding(\"utf-8\")\n",
        "    is_py3 = False\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_hWgMYDdHmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def native_word(word, encoding='utf-8'):\n",
        "    \"\"\"如果在python2下面使用python3训练的模型，可考虑调用此函数转化一下字符编码\"\"\"\n",
        "    if not is_py3:\n",
        "        return word.encode(encoding)\n",
        "    else:\n",
        "        return word\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC8H1WBjdKMm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def native_content(content):\n",
        "    if not is_py3:\n",
        "        return content.decode('utf-8')\n",
        "    else:\n",
        "        return content\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFkRTIiFdQ12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def open_file(filename, mode='r'):\n",
        "    \"\"\"\n",
        "    常用文件操作，可在python2和python3间切换.\n",
        "    mode: 'r' or 'w' for read or write\n",
        "    \"\"\"\n",
        "    if is_py3:\n",
        "        return open(filename, mode, encoding='utf-8', errors='ignore')\n",
        "    else:\n",
        "        return open(filename, mode)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FbSZUtBdTZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def read_file(filename):\n",
        "    \"\"\"读取文件数据\"\"\"\n",
        "    contents, labels = [], []\n",
        "    with open_file(filename) as f:\n",
        "        for line in f:\n",
        "            try:\n",
        "                label, content = line.strip().split('\\t')\n",
        "                if content:\n",
        "                    contents.append(list(native_content(content)))\n",
        "                    labels.append(native_content(label))\n",
        "            except:\n",
        "                pass\n",
        "    return contents, labels\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8MQDgwGdVj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def build_vocab(train_dir, vocab_dir, vocab_size=5000):\n",
        "    \"\"\"根据训练集构建词汇表，存储\"\"\"\n",
        "    data_train, _ = read_file(train_dir)\n",
        "\n",
        "    all_data = []\n",
        "    for content in data_train:\n",
        "        all_data.extend(content)\n",
        "\n",
        "    counter = Counter(all_data)\n",
        "    count_pairs = counter.most_common(vocab_size - 1)\n",
        "    words, _ = list(zip(*count_pairs))\n",
        "    # 添加一个 <PAD> 来将所有文本pad为同一长度\n",
        "    words = ['<PAD>'] + list(words)\n",
        "    open_file(vocab_dir, mode='w').write('\\n'.join(words) + '\\n')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj0Ce0dEdX0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def read_vocab(vocab_dir):\n",
        "    \"\"\"读取词汇表\"\"\"\n",
        "    # words = open_file(vocab_dir).read().strip().split('\\n')\n",
        "    with open_file(vocab_dir) as fp:\n",
        "        # 如果是py2 则每个值都转化为unicode\n",
        "        words = [native_content(_.strip()) for _ in fp.readlines()]\n",
        "    word_to_id = dict(zip(words, range(len(words))))\n",
        "    return words, word_to_id\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndMYEMOedZh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def read_category():\n",
        "    \"\"\"读取分类目录，固定\"\"\"\n",
        "    categories = ['体育', '财经', '房产', '家居', '教育', '科技', '时尚', '时政', '游戏', '娱乐']\n",
        "\n",
        "    categories = [native_content(x) for x in categories]\n",
        "\n",
        "    cat_to_id = dict(zip(categories, range(len(categories))))\n",
        "\n",
        "    return categories, cat_to_id\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3ooZV2BdbGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def to_words(content, words):\n",
        "    \"\"\"将id表示的内容转换为文字\"\"\"\n",
        "    return ''.join(words[x] for x in content)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaN44Vfrdcyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def process_file(filename, word_to_id, cat_to_id, max_length=600):\n",
        "    \"\"\"将文件转换为id表示\"\"\"\n",
        "    contents, labels = read_file(filename)\n",
        "\n",
        "    data_id, label_id = [], []\n",
        "    for i in range(len(contents)):\n",
        "        data_id.append([word_to_id[x] for x in contents[i] if x in word_to_id])\n",
        "        label_id.append(cat_to_id[labels[i]])\n",
        "\n",
        "    # 使用keras提供的pad_sequences来将文本pad为固定长度\n",
        "    x_pad = kr.preprocessing.sequence.pad_sequences(data_id, max_length)\n",
        "    y_pad = kr.utils.to_categorical(label_id, num_classes=len(cat_to_id))  # 将标签转换为one-hot表示\n",
        "\n",
        "    return x_pad, y_pad\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXtl8WZpdet1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def batch_iter(x, y, batch_size=64):\n",
        "    \"\"\"生成批次数据\"\"\"\n",
        "    data_len = len(x)\n",
        "    num_batch = int((data_len - 1) / batch_size) + 1\n",
        "\n",
        "    indices = np.random.permutation(np.arange(data_len))\n",
        "    x_shuffle = x[indices]\n",
        "    y_shuffle = y[indices]\n",
        "\n",
        "    for i in range(num_batch):\n",
        "        start_id = i * batch_size\n",
        "        end_id = min((i + 1) * batch_size, data_len)\n",
        "        yield x_shuffle[start_id:end_id], y_shuffle[start_id:end_id]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}